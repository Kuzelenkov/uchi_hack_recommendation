{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flask Uchihack.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSwVBuxAEj41",
        "outputId": "344e2cf9-0914-4649-9ef0-1476c9853497"
      },
      "source": [
        "pip install flask_ngrok"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flask_ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (1.1.4)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask_ngrok) (2.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2021.5.30)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Naa4MZVOEpIX",
        "outputId": "a9cc2a68-6c7b-4d24-842d-bb9cd2ece859"
      },
      "source": [
        "pip install pymorphy2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████                          | 10 kB 23.3 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 30 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 40 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 55 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 7.9 MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhNszHHSEWvp",
        "outputId": "b74d91ab-c368-4c7b-f086-36c41619b11f"
      },
      "source": [
        "from flask import Flask, jsonify, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "import pymorphy2\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "\n",
        "def lemm(data):\n",
        "  if type(data) == str:\n",
        "    data = data.split()\n",
        "  morph = pymorphy2.MorphAnalyzer()\n",
        "  stop_words = set(stopwords.words('russian'))\n",
        "  words = [re.sub(r'\\d+', '', i.lower()).replace('»', '').replace('«', '').replace('’', '').translate(str.maketrans('', '', string.punctuation)) for i in data if i not in stop_words]\n",
        "  words = filter(None, words)\n",
        "  tokens = []\n",
        "  for i in words:\n",
        "    tokens.append([morph.parse(w)[0].normal_form for w in nltk.word_tokenize(i)])\n",
        "  tokens = [sorted(list([j for j in i])) for i in tokens]\n",
        "  return tokens\n",
        "\n",
        "\n",
        "def get_tags(data):\n",
        "  list_tags = []\n",
        "  for i in data:\n",
        "    list_list_tag = []\n",
        "    if 'шар' and 'урна' in i:\n",
        "      list_list_tag.append('Задача про шары и урну')\n",
        "    elif 'урна' in i:\n",
        "      list_list_tag.append('Задача про урну')\n",
        "    elif 'шар' in i:\n",
        "      list_list_tag.append('Задача про шары')\n",
        "    if 'классический' and 'вероятность' in i:\n",
        "      list_list_tag.append('Классическая вероятность')\n",
        "    if 'синоним' in i:\n",
        "      list_list_tag.append('Синонимы')\n",
        "    if 'значение' and 'слово' in i:\n",
        "      list_list_tag.append('Значение слова')\n",
        "    if ('просклонять' or 'склонение') and 'русский язык' in i:\n",
        "      list_list_tag.append('Склонение')\n",
        "    if 'цикл' and 'while' in i:\n",
        "      list_list_tag.append('Цикл while')\n",
        "    elif 'цикл' and 'for' in i:\n",
        "      list_list_tag.append('Цикл for')\n",
        "    elif 'цикл' in i:\n",
        "      list_list_tag.append('Цикл')\n",
        "    if 'грамматика' in i:\n",
        "      list_list_tag.append('Грамматика')\n",
        "    if 'данные' and 'тип' and 'float' in i:\n",
        "      list_list_tag.append('Тип данных float')\n",
        "    elif 'данные' and 'тип' and ('int' or 'integer') in i:\n",
        "      list_list_tag.append('Тип данных integer')\n",
        "    elif 'данные' and 'тип' and ('str' or 'string') in i:\n",
        "      list_list_tag.append('Тип данных string')\n",
        "    elif 'данные' and 'тип' in i:\n",
        "      list_list_tag.append('Типы данных')\n",
        "    if 'pascal' in i:\n",
        "      list_list_tag.append('Pascal')\n",
        "    if 'javascript' in i:\n",
        "      list_list_tag.append('Javascript')\n",
        "    if 'php' in i:\n",
        "      list_list_tag.append('Php')\n",
        "    if 'java' in i:\n",
        "      list_list_tag.append('Java')\n",
        "    if 'html' in i:\n",
        "      list_list_tag.append('Html')\n",
        "    if 'css' in i:\n",
        "      list_list_tag.append('Css')\n",
        "    if 'python' in i:\n",
        "      list_list_tag.append('Python')\n",
        "    if 'система' and 'счисление' and 'восьмеричный' in i:\n",
        "      list_list_tag.append('Восьмеричная система счисления')\n",
        "    elif 'система' and 'счисление' and 'десятеричный' in i:\n",
        "      list_list_tag.append('Десятеричная система счисления')\n",
        "    elif 'система' and 'счисление' and 'двоичный' in i:\n",
        "      list_list_tag.append('Двоичная система счисления')\n",
        "    elif 'основание' and 'система' and 'счисление' in i:\n",
        "      list_list_tag.append('Основание системы счисления')\n",
        "    elif 'система' and 'счисление' and 'римский' in i:\n",
        "      list_list_tag.append('Римская система счисления')\n",
        "    if 'общий' and 'определение' in i:\n",
        "      list_list_tag.append('Общие определения')\n",
        "    if 'перевод' in i:\n",
        "      list_list_tag.append('Перевод')\n",
        "    if 'дата' in i:\n",
        "      list_list_tag.append('Дата')\n",
        "    if 'крещение' and 'русь' in i:\n",
        "      list_list_tag.append('Крещение Руси')\n",
        "    if 'война' and 'второй' and 'мировой' in i:\n",
        "      list_list_tag.append('Вторая мировая война')\n",
        "    elif 'война' in i:\n",
        "      list_list_tag.append('Война')\n",
        "    if 'сражение' in i:\n",
        "      list_list_tag.append('Сражение')\n",
        "    if 'византия' in i:\n",
        "      list_list_tag.append('Византия')\n",
        "    if 'гриб' and 'царство' in i:\n",
        "      list_list_tag.append('Царство грибы')\n",
        "    if 'корень' and 'уравнение' in i:\n",
        "      list_list_tag.append('Корень уравнения')\n",
        "    elif 'уравнение' in i:\n",
        "      list_list_tag.append('Уравнение')\n",
        "    if 'математика' in i:\n",
        "      list_list_tag.append('Математика')\n",
        "    if 'русский язык' in i:\n",
        "      list_list_tag.append('Русский язык')\n",
        "    if 'информатика' in i:\n",
        "      list_list_tag.append('Информатика')\n",
        "    if 'история' and 'событие' in i:\n",
        "      list_list_tag.append('Историческое событие')\n",
        "    if 'история' in i:\n",
        "      list_list_tag.append('История')\n",
        "    if 'английский язык' in i:\n",
        "      list_list_tag.append('Английский язык')\n",
        "    if 'биология' in i:\n",
        "      list_list_tag.append('Биология')\n",
        "    list_tags.append(list_list_tag)\n",
        "  return list_tags\n",
        "\n",
        "\n",
        "def get_similar_quests(data, sphere, subsphere, is_solved):\n",
        "  list_index = []\n",
        "  for i in df.loc[(df['subject'] == sphere.lower()) & (df['topic'] == subsphere) & (df['is_solved'] == is_solved)].index:\n",
        "    if len([j for j in df.iloc[i]['tags'].split(', ') if j in data]) / len(data) > 0.5:\n",
        "      list_index.append(i)\n",
        "  return df.iloc[list_index]\n",
        "\n",
        "\n",
        "def create_new_tags_all(sphere, subsphere, title):\n",
        "  return list(set([''.join(i) for i in get_tags(lemm(title) + lemm(subsphere) + [sphere.lower()]) if i != []]))\n",
        "\n",
        "\n",
        "def create_new_tags(sphere, subsphere):\n",
        "  return list(set([''.join(i) for i in get_tags(lemm(subsphere) + [sphere.lower()]) if i != []]))\n",
        "\n",
        "\n",
        "def get_recommendation(solved_id):\n",
        "  t = pd.DataFrame(columns = df.columns)\n",
        "  for i in df.loc[(df['solved_id'] == solved_id)].index:\n",
        "    t = pd.concat([t, get_similar_quests(df.iloc[i]['tags'].split(', '), df.iloc[i]['subject'], df.iloc[i]['topic'], 0)], ignore_index=True)\n",
        "    t = t.drop_duplicates()\n",
        "  t = t.loc[t['author_id'] != solved_id]\n",
        "  return t\n",
        "\n",
        "\n",
        "def far_meaning(quest: str, df, sphere, subsphere, threshold=0.5):\n",
        "  quest = sorted([i[0] for i in lemm(quest.split()) if i != []])\n",
        "  corpus = [' '.join(i) for i in lemm(df.loc[(df['subject'] == sphere.lower()) & (df['topic'] == subsphere)]['title'])]\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  X = vectorizer.fit_transform(corpus)\n",
        "  y = vectorizer.transform(quest)\n",
        "  similarities = {}\n",
        "  for i in range(len(corpus)):\n",
        "    similarities[i] = sum([i for i in cosine_similarity(X[i], y)[0]])\n",
        "  similarities = {k: v for k, v in sorted(similarities.items(), key=lambda item: item[1], reverse=True)}\n",
        "  match = df.iloc[corpus.index(corpus[list(similarities.keys())[0]])]\n",
        "  if list(similarities.values())[0] < threshold:\n",
        "    match = ''\n",
        "  return match\n",
        "\n",
        "\n",
        "@app.route('/', methods=['POST'])\n",
        "def get_answer():\n",
        "  if request.method == 'POST':\n",
        "    data = request.get_json()\n",
        "    \n",
        "    #df = pd.read_csv('uchi.csv')\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Хакатоны/Uchihack/uchi.csv')\n",
        "    if data['subject'] and data['topic'] and data['title'] and request == 'get_questions':\n",
        "      if far_meaning(data['title'], df, data['subject'], data['topic']) != '':\n",
        "        val = df.loc[df.index == far_meaning(data['title'], df, data['subject'], data['topic'])['Unnamed: 0']] + get_similar_quests(create_new_tags_all(data['subject'], data['topic'], data['title']), data['subject'], data['topic'], 1)\n",
        "        val = val.drop_duplicates()\n",
        "      else:\n",
        "        val = get_similar_quests(create_new_tags_all(data['subject'], data['topic'], data['title']), data['subject'], data['topic'], 1)\n",
        "    elif data['subject'] and data['topic'] and request == 'get_questions':\n",
        "      val = get_similar_quests(create_new_tags(data['subject'], data['topic']), data['subject'], data['topic'], 1).index\n",
        "    elif data['solved_id'] and request == 'get_recommendation':\n",
        "      val = get_recommendation(data['solved_id'])\n",
        "    val = [i for i in val.index]\n",
        "    return jsonify({'question_id': val})\n",
        "  \n",
        "\n",
        "@app.route('/changes', methods=['POST'])\n",
        "def update_data():\n",
        "  if request.method == 'POST':\n",
        "    #df = pd.read_csv('uchi.csv')\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Хакатоны/Uchihack/uchi.csv')\n",
        "    data = request.get_json()\n",
        "    if len(df.loc[df['Unnamed: 0'] == data['question_id']]) < 1:\n",
        "      df['Unnamed: 0'] = [i for i in df['Unnamed: 0']] + data['question_id']\n",
        "    df.loc[df['Unnamed: 0'] == data['question_id'], [data.keys()]] = data.values()\n",
        "    #df.to_csv('uchihack.csv', index=False)\n",
        "    df.to_csv('/content/drive/MyDrive/Хакатоны/Uchihack/uchi.csv', index=False)\n",
        "    return jsonify({'request': 'OK'})\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://fd97-35-224-55-187.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCWi9DleEgsy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}